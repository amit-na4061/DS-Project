{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef51a7bc",
   "metadata": {
    "papermill": {
     "duration": 0.005972,
     "end_time": "2024-05-18T20:41:05.105593",
     "exception": false,
     "start_time": "2024-05-18T20:41:05.099621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Classification with PyTorch\n",
    "\n",
    "This Python notebook demonstrates how to build an image classification model using PyTorch. We will use a custom dataset, define a convolutional neural network (CNN) architecture, train the model, and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70b72f",
   "metadata": {
    "papermill": {
     "duration": 0.005034,
     "end_time": "2024-05-18T20:41:05.116327",
     "exception": false,
     "start_time": "2024-05-18T20:41:05.111293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "We start by importing the necessary libraries for our project:\n",
    "\n",
    "- `os` for file and directory operations\n",
    "- `torch` and `torch.nn` for building and training the neural network\n",
    "- `torch.optim` for optimization algorithms\n",
    "- `torch.utils.data` for creating data loaders and custom datasets\n",
    "- `torchvision.transforms` for image transformations\n",
    "- `PIL` for image loading and manipulation\n",
    "- `matplotlib.pyplot` for visualizing images and plots\n",
    "- `random` for random number generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038b40e9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 6.857636,
     "end_time": "2024-05-18T20:41:11.979447",
     "exception": false,
     "start_time": "2024-05-18T20:41:05.121811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b365b74",
   "metadata": {
    "papermill": {
     "duration": 0.005165,
     "end_time": "2024-05-18T20:41:11.990248",
     "exception": false,
     "start_time": "2024-05-18T20:41:11.985083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom Dataset Class\n",
    "\n",
    "We define a custom `WasteDataset` class that inherits from PyTorch's `Dataset` class. This class is responsible for loading and preprocessing the images from the dataset.\n",
    "\n",
    "### Initialization\n",
    "\n",
    "The `__init__` method takes the following parameters:\n",
    "- `root_dir`: The root directory containing the dataset images.\n",
    "- `split`: The dataset split (train, validation, or test).\n",
    "- `transform`: Optional image transformations to be applied.\n",
    "\n",
    "Inside the `__init__` method, we:\n",
    "1. Store the `root_dir`, `transform`, and `split` parameters.\n",
    "2. Get the list of class names by listing the directories in `root_dir`.\n",
    "3. Initialize empty lists for `image_paths` and `labels`.\n",
    "4. Iterate over each class directory and its subfolders ('default' and 'real_world').\n",
    "5. Shuffle the image names in each subfolder.\n",
    "6. Based on the `split` parameter, select a portion of the images (60% for train, 20% for validation, 20% for test).\n",
    "7. Append the image paths and corresponding labels to the respective lists.\n",
    "\n",
    "### Length and Item Retrieval\n",
    "\n",
    "The `__len__` method returns the total number of images in the dataset.\n",
    "\n",
    "The `__getitem__` method takes an `index` and returns the image and its corresponding label at that index. It:\n",
    "1. Retrieves the image path and label using the provided index.\n",
    "2. Opens the image using `Image.open()` and converts it to RGB format.\n",
    "3. Applies the specified image transformations, if any.\n",
    "4. Returns the transformed image and its label.\n",
    "\n",
    "This custom dataset class allows us to easily load and preprocess the waste images for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f19c37",
   "metadata": {
    "papermill": {
     "duration": 0.01983,
     "end_time": "2024-05-18T20:41:12.015186",
     "exception": false,
     "start_time": "2024-05-18T20:41:11.995356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the dataset class (modified to include a split parameter)\n",
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for subfolder in ['default', 'real_world']:\n",
    "                subfolder_dir = os.path.join(class_dir, subfolder)\n",
    "                image_names = os.listdir(subfolder_dir)\n",
    "                random.shuffle(image_names)\n",
    "                \n",
    "                if split == 'train':\n",
    "                    image_names = image_names[:int(0.6 * len(image_names))]\n",
    "                elif split == 'val':\n",
    "                    image_names = image_names[int(0.6 * len(image_names)):int(0.8 * len(image_names))]\n",
    "                else:  # split == 'test'\n",
    "                    image_names = image_names[int(0.8 * len(image_names)):]\n",
    "                \n",
    "                for image_name in image_names:\n",
    "                    self.image_paths.append(os.path.join(subfolder_dir, image_name))\n",
    "                    self.labels.append(i)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffc673",
   "metadata": {
    "papermill": {
     "duration": 0.004918,
     "end_time": "2024-05-18T20:41:12.025587",
     "exception": false,
     "start_time": "2024-05-18T20:41:12.020669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN Model Architecture\n",
    "\n",
    "We define a convolutional neural network (CNN) model called `CNN` that inherits from PyTorch's `nn.Module` class. This model architecture consists of convolutional layers, pooling layers, and fully connected layers.\n",
    "\n",
    "### Initialization\n",
    "\n",
    "The `__init__` method takes the following parameter:\n",
    "- `num_classes`: The number of output classes in the classification task.\n",
    "\n",
    "Inside the `__init__` method, we define the layers of the CNN:\n",
    "1. `conv1`: A 2D convolutional layer with 3 input channels, 32 output channels, a kernel size of 3, stride of 1, and padding of 1.\n",
    "2. `relu`: A ReLU activation function.\n",
    "3. `maxpool`: A 2D max pooling layer with a kernel size of 2 and stride of 2.\n",
    "4. `conv2`: Another 2D convolutional layer with 32 input channels, 64 output channels, a kernel size of 3, stride of 1, and padding of 1.\n",
    "5. `fc1`: A fully connected layer that takes the flattened output of `conv2` and maps it to 512 features.\n",
    "6. `fc2`: The final fully connected layer that takes the 512 features and maps them to the number of output classes.\n",
    "\n",
    "### Forward Pass\n",
    "\n",
    "The `forward` method defines the forward pass of the CNN model. It takes an input tensor `x` and applies the following operations:\n",
    "1. Pass `x` through `conv1`, followed by `relu` activation and `maxpool`.\n",
    "2. Pass the output through `conv2`, followed by `relu` activation and `maxpool`.\n",
    "3. Flatten the output of `conv2` using `x.view(x.size(0), -1)`.\n",
    "4. Pass the flattened tensor through `fc1`, followed by `relu` activation.\n",
    "5. Pass the output of `fc1` through `fc2` to obtain the final output.\n",
    "\n",
    "The output of the `forward` method represents the predicted class scores for each input sample.\n",
    "\n",
    "This CNN architecture is designed to learn hierarchical features from the input images and make predictions based on those features. The convolutional layers capture local patterns, the pooling layers reduce spatial dimensions, and the fully connected layers perform the final classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98e6657",
   "metadata": {
    "papermill": {
     "duration": 0.01585,
     "end_time": "2024-05-18T20:41:12.046721",
     "exception": false,
     "start_time": "2024-05-18T20:41:12.030871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d49e8",
   "metadata": {
    "papermill": {
     "duration": 0.004844,
     "end_time": "2024-05-18T20:41:12.056898",
     "exception": false,
     "start_time": "2024-05-18T20:41:12.052054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Path and Hyperparameters\n",
    "\n",
    "We set the following dataset path and hyperparameters:\n",
    "- `dataset_path`: The path to the directory containing the dataset images.\n",
    "- `batch_size`: The number of samples per batch during training and evaluation.\n",
    "- `num_epochs`: The number of epochs to train the model.\n",
    "- `learning_rate`: The learning rate for the optimizer.\n",
    "\n",
    "These hyperparameters can be adjusted based on the specific requirements and available computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58489a2c",
   "metadata": {
    "papermill": {
     "duration": 0.011521,
     "end_time": "2024-05-18T20:41:12.073647",
     "exception": false,
     "start_time": "2024-05-18T20:41:12.062126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the dataset path and hyperparameters\n",
    "dataset_path = 'C:\\\\Users\\\\amitn\\\\Downloads\\\\Dataset for project\\\\Master Project\\\\Deep Learning\\\\CNN\\\\images'\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8121739",
   "metadata": {
    "papermill": {
     "duration": 0.00507,
     "end_time": "2024-05-18T20:41:12.083997",
     "exception": false,
     "start_time": "2024-05-18T20:41:12.078927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing and Loaders\n",
    "\n",
    "We define a composition of image transformations using `transforms.Compose`:\n",
    "1. `transforms.Resize((224, 224))`: Resizes the images to a fixed size of (224, 224) pixels.\n",
    "2. `transforms.ToTensor()`: Converts the images to PyTorch tensors.\n",
    "3. `transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])`: Normalizes the image tensors using the specified mean and standard deviation values.\n",
    "\n",
    "These transformations ensure that the images are preprocessed consistently before being fed into the model.\n",
    "\n",
    "We create instances of the `WasteDataset` class for the train, validation, and test splits, passing the `dataset_path`, `split`, and `transform` parameters. This allows us to load the dataset images with the specified transformations for each split.\n",
    "\n",
    "Finally, we create data loaders for each dataset using `DataLoader`:\n",
    "- `train_dataloader`: Loads the training data in batches of size `batch_size` and shuffles the samples.\n",
    "- `val_dataloader`: Loads the validation data in batches of size `batch_size` without shuffling.\n",
    "- `test_dataloader`: Loads the test data in batches of size `batch_size` without shuffling.\n",
    "\n",
    "The data loaders provide an efficient way to iterate over the dataset during training and evaluation, handling batching and shuffling as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154d0672",
   "metadata": {
    "papermill": {
     "duration": 2.129178,
     "end_time": "2024-05-18T20:41:14.218217",
     "exception": false,
     "start_time": "2024-05-18T20:41:12.089039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\amitn\\\\Downloads\\\\Dataset for project\\\\Master Project\\\\Deep Learning\\\\CNN\\\\images\\\\Check\\\\default'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create the datasets and data loaders\u001b[39;00m\n\u001b[0;32m      2\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[0;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      5\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[0;32m      6\u001b[0m ])\n\u001b[1;32m----> 7\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m WasteDataset(dataset_path, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m      8\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m WasteDataset(dataset_path, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheck\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m      9\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m WasteDataset(dataset_path, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m, in \u001b[0;36mWasteDataset.__init__\u001b[1;34m(self, root_dir, split, transform)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subfolder \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal_world\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m     subfolder_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_dir, subfolder)\n\u001b[1;32m---> 14\u001b[0m     image_names \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(subfolder_dir)\n\u001b[0;32m     15\u001b[0m     random\u001b[38;5;241m.\u001b[39mshuffle(image_names)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\amitn\\\\Downloads\\\\Dataset for project\\\\Master Project\\\\Deep Learning\\\\CNN\\\\images\\\\Check\\\\default'"
     ]
    }
   ],
   "source": [
    "# Create the datasets and data loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_dataset = WasteDataset(dataset_path, split='Train', transform=transform)\n",
    "val_dataset = WasteDataset(dataset_path, split='Check', transform=transform)\n",
    "test_dataset = WasteDataset(dataset_path, split='Test', transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086fd90",
   "metadata": {
    "papermill": {
     "duration": 0.004946,
     "end_time": "2024-05-18T20:41:14.228861",
     "exception": false,
     "start_time": "2024-05-18T20:41:14.223915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Initialization\n",
    "\n",
    "We create an instance of the `CNN` model, passing the `num_classes` parameter. The `num_classes` is determined by the number of unique classes in the dataset, which is obtained using `len(dataset.classes)`. This ensures that the model's output layer has the correct number of units corresponding to the number of classes.\n",
    "\n",
    "The model is then moved to the GPU using `.to('cuda')` to take advantage of GPU acceleration for faster training and inference.\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "We define the loss function using `nn.CrossEntropyLoss()`. Cross-entropy loss is commonly used for multi-class classification tasks. It measures the dissimilarity between the predicted class probabilities and the true class labels, providing a measure of how well the model is performing.\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "We create an optimizer using `optim.Adam()`, passing the model's parameters (`model.parameters()`) and the learning rate (`lr=learning_rate`). Adam (Adaptive Moment Estimation) is a popular optimization algorithm that adapts the learning rate for each parameter based on the first and second moments of the gradients. It combines the benefits of AdaGrad and RMSprop optimizers.\n",
    "\n",
    "The optimizer is responsible for updating the model's parameters during the training process based on the computed gradients and the specified learning rate.\n",
    "\n",
    "With the model, loss function, and optimizer defined, we are ready to proceed with training the CNN model on the waste classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877724b",
   "metadata": {
    "papermill": {
     "duration": 1.44906,
     "end_time": "2024-05-18T20:41:15.683238",
     "exception": false,
     "start_time": "2024-05-18T20:41:14.234178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the model, loss function, and optimizer\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = CNN(num_classes).to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e557c",
   "metadata": {
    "papermill": {
     "duration": 0.005881,
     "end_time": "2024-05-18T20:41:15.695595",
     "exception": false,
     "start_time": "2024-05-18T20:41:15.689714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "We define lists `train_losses` and `val_losses` to store the training and validation losses for each epoch, respectively. These lists will be used to monitor the model's performance during training.\n",
    "\n",
    "The training loop iterates over the specified number of epochs (`num_epochs`). In each epoch, we perform the following steps:\n",
    "\n",
    "### Training Phase\n",
    "\n",
    "1. Set the model to training mode using `model.train()`. This enables dropout and batch normalization layers to update their parameters during training.\n",
    "\n",
    "2. Initialize the `train_loss` variable to keep track of the cumulative training loss for the current epoch.\n",
    "\n",
    "3. Iterate over the training data using `train_dataloader`:\n",
    "  - Move the images and labels to the GPU using `.to('cuda')`.\n",
    "  - Forward pass: Pass the images through the model to obtain the predicted outputs.\n",
    "  - Compute the loss using the defined criterion (`criterion(outputs, labels)`).\n",
    "  - Backward pass: Zero the gradients using `optimizer.zero_grad()`, compute the gradients using `loss.backward()`, and update the model parameters using `optimizer.step()`.\n",
    "  - Accumulate the training loss for the current batch.\n",
    "\n",
    "4. Compute the average training loss for the epoch by dividing the cumulative loss by the total number of training samples.\n",
    "\n",
    "5. Append the average training loss to the `train_losses` list.\n",
    "\n",
    "### Validation Phase\n",
    "\n",
    "1. Set the model to evaluation mode using `model.eval()`. This disables dropout and batch normalization layers during inference.\n",
    "\n",
    "2. Initialize the `val_loss` variable to keep track of the cumulative validation loss for the current epoch.\n",
    "\n",
    "3. Disable gradient computation using `torch.no_grad()` to speed up the validation process.\n",
    "\n",
    "4. Iterate over the validation data using `val_dataloader`:\n",
    "  - Move the images and labels to the GPU using `.to('cuda')`.\n",
    "  - Forward pass: Pass the images through the model to obtain the predicted outputs.\n",
    "  - Compute the loss using the defined criterion (`criterion(outputs, labels)`).\n",
    "  - Accumulate the validation loss for the current batch.\n",
    "\n",
    "5. Compute the average validation loss for the epoch by dividing the cumulative loss by the total number of validation samples.\n",
    "\n",
    "6. Append the average validation loss to the `val_losses` list.\n",
    "\n",
    "After each epoch, we print the current epoch number, training loss, and validation loss to monitor the progress of the training process.\n",
    "\n",
    "Once all epochs are completed, we print a message indicating that the training is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a67ff",
   "metadata": {
    "papermill": {
     "duration": 409.561134,
     "end_time": "2024-05-18T20:48:05.262712",
     "exception": false,
     "start_time": "2024-05-18T20:41:15.701578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lists to store the training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2c1c3",
   "metadata": {
    "papermill": {
     "duration": 0.005655,
     "end_time": "2024-05-18T20:48:05.273970",
     "exception": false,
     "start_time": "2024-05-18T20:48:05.268315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Results Visualization\n",
    "\n",
    "In this section, we visualize the results from training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7697c",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.315425,
     "end_time": "2024-05-18T20:48:05.594828",
     "exception": false,
     "start_time": "2024-05-18T20:48:05.279403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138ebb5",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 1.49525,
     "end_time": "2024-05-18T20:48:07.096357",
     "exception": false,
     "start_time": "2024-05-18T20:48:05.601107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform sample inferences on random test images with different labels\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    indices = list(range(len(test_dataset)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    selected_images = []\n",
    "    selected_labels = []\n",
    "    selected_predicted = []\n",
    "    \n",
    "    for index in indices:\n",
    "        image, label = test_dataset[index]\n",
    "        image = image.unsqueeze(0).to('cuda')\n",
    "        \n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        if label not in selected_labels:\n",
    "            selected_images.append(image)\n",
    "            selected_labels.append(label)\n",
    "            selected_predicted.append(predicted.item())\n",
    "        \n",
    "        if len(selected_labels) == 9:\n",
    "            break\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(9):\n",
    "        axes[i].imshow(selected_images[i].squeeze().cpu().permute(1, 2, 0))\n",
    "        axes[i].set_title(f\"True: {train_dataset.classes[selected_labels[i]]}\\nPredicted: {train_dataset.classes[selected_predicted[i]]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249844a6",
   "metadata": {
    "papermill": {
     "duration": 0.014211,
     "end_time": "2024-05-18T20:48:07.125429",
     "exception": false,
     "start_time": "2024-05-18T20:48:07.111218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5037535,
     "sourceId": 8452655,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 427.496531,
   "end_time": "2024-05-18T20:48:09.615726",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-18T20:41:02.119195",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
