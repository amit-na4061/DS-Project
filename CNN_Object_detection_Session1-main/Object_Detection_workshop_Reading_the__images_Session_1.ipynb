{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWMPHJn9i5eA"
   },
   "source": [
    "**OpenCV (Open Source Computer Vision Library)**\n",
    "\n",
    " It is a powerful open-source computer vision and machine learning software library. It contains more than 2500 optimized algorithms for a wide range of tasks such as object detection, face recognition, and image processing.\n",
    "\n",
    "Some of the Important Concepts\n",
    "\n",
    "**1. RGB**\n",
    "\n",
    "RGB stands for\n",
    "-  Red,\n",
    "\n",
    "- Green, and\n",
    "\n",
    "- Blue.\n",
    "\n",
    "It is a color model in which colors are created by combining these three primary colors in different intensities. In an image:\n",
    "\n",
    "Each pixel is represented by three values, corresponding to the intensities of red, green, and blue.\n",
    "\n",
    "The value of each channel ranges from 0 to 255.\n",
    "\n",
    "For instance,\n",
    "\n",
    "- (255, 0, 0) represents red,\n",
    "\n",
    "- (0, 255, 0) represents green,\n",
    "\n",
    "- and (0, 0, 255) represents blue.\n",
    "\n",
    "\n",
    "**2. BGR**\n",
    "\n",
    "BGR is another color model, similar to RGB, but with the order of colors reversed. **This is the default color space in OpenCV:**\n",
    "\n",
    "Each pixel is represented by three values, but the order is\n",
    "\n",
    "- Blue,\n",
    "\n",
    "- Green, and\n",
    "\n",
    "- Red.\n",
    "\n",
    "The BGR format is used in many image file formats and computer vision applications because it aligns with how certain hardware and software handle color.\n",
    "\n",
    "\n",
    "**3. Gray**\n",
    "\n",
    "Gray (Grayscale) images contain only intensity information, not color. In a grayscale image:\n",
    "\n",
    "Each pixel is represented by a single value that indicates the intensity of light at that point ranging from\n",
    "\n",
    "- 0 (black) to\n",
    "\n",
    "- 255 (white).\n",
    "\n",
    "Grayscale images are often used in image processing tasks because they reduce the complexity of the data.\n",
    "\n",
    "\n",
    "**4. Color**\n",
    "\n",
    "Color images are those that contain color information and are typically represented in RGB or BGR formats. These images:\n",
    "\n",
    "Include multiple channels (typically three for RGB/BGR) that combine to produce a full range of colors.\n",
    "Are used in tasks where color information is important, such as object recognition and tracking.\n",
    "\n",
    "**5. How 0 to 255 is Implemented**\n",
    "\n",
    "The range from 0 to 255 is used to represent the intensity of each color channel or pixel value. This range comes from the 8-bit depth commonly used in digital imaging:\n",
    "\n",
    "An 8-bit number can represent 256 different values (from 0 to 255).\n",
    "\n",
    "This allows for 256 levels of intensity for each channel in an RGB or BGR image, which is sufficient for most visual applications to create a wide range of colors and grayscale intensities.\n",
    "\n",
    "For example, a pixel value of (0, 0, 0) in RGB/BGR represents black, while (255, 255, 255) represents white. Intermediate values represent varying shades and colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "6TOyhZkVdseW",
    "outputId": "280a00f2-a629-471f-88af-e0b55fbb64c9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m image\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/Benjamin-Franklin.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "image=cv2.imread(\"/content/Benjamin-Franklin.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "41tjUSKLhcGN",
    "outputId": "136dc120-65d0-430c-baa1-e986eec26872"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "image=cv2.imread(\"/content/Benjamin-Franklin.jpg\")\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "750RXOtApBai"
   },
   "source": [
    "**image.shape**\n",
    "\n",
    "In OpenCV, the shape attribute of an image provides information about the dimensions and the number of channels of the image. Specifically, image.shape returns a tuple containing the following elements:\n",
    "\n",
    "- Height: The number of rows (pixels) in the image.\n",
    "\n",
    "- Width: The number of columns (pixels) in the image.\n",
    "\n",
    "- Number of Channels: The number of color channels in the image (if applicable).\n",
    "\n",
    "**grayscale image**\n",
    "\n",
    "- image.shape will return a tuple with two values:\n",
    "\n",
    "    - (height, width).\n",
    "\n",
    "**color image** (like an RGB or BGR image),\n",
    "\n",
    "- image.shape will return a tuple with three values:\n",
    "\n",
    "    - (height, width, channels).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovYFbm2epDKR",
    "outputId": "f6dc2cc4-af58-43cf-b260-72779fd23907"
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-XuPdfipFz0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDtvmHXJGigb"
   },
   "source": [
    "**Open CV behaviour**\n",
    "\n",
    "- By Default OpenCV reads the data in BGR(Blue, Green,RED) Format\n",
    "\n",
    "- BGR is a color imgae\n",
    "\n",
    "- Using OpenCV library we can convert in Color to Gray\n",
    "\n",
    "- Using OpenCV library we can Convert RGB to BGR\n",
    "\n",
    "- In Python there are many libraries for visulations or plot the images\n",
    "\n",
    "- Some are\n",
    "\n",
    "  - OpenCV\n",
    "\n",
    "  - Matplotlib\n",
    "\n",
    "  - Pillow\n",
    "\n",
    "  - Seaborn\n",
    "\n",
    "  - Bokhe\n",
    "\n",
    "  - Plotly etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "vT0ADljJh8pO",
    "outputId": "e0d5bfcf-e5f8-448a-c987-782dcbe21ddb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image in BGR color space (default)\n",
    "image_bgr = cv2.imread('/content/Benjamin-Franklin.jpg')\n",
    "\n",
    "# Convert BGR to RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert BGR to Grayscale\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the images\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(image_bgr)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(image_rgb)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(image_gray)\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gl76oO_4p1_W",
    "outputId": "32f888c2-80bd-4689-eb3e-6ca009e0d42f"
   },
   "outputs": [],
   "source": [
    "print('shape of BGR Color:',image_bgr.shape) # color image\n",
    "print('shape of RGB Color:',image_rgb.shape) # Color image\n",
    "print('shape of Gray Color:',image_gray.shape) # Black and white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i2Ke4GnocKz"
   },
   "source": [
    "## Writing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XuJ9aTfmIPI",
    "outputId": "cd10e93e-97e7-4173-ffc0-a1795fdca21b"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imwrite('output_gray.jpg', image_gray) # less in kb\n",
    "cv2.imwrite('output_gray.png', image_gray) # more in kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztbNiRloHX-d",
    "outputId": "607f29ac-63ec-46fb-f43a-fab7f6624450"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imwrite('output_bgr.jpg', image_bgr) # less in kb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JV938UGH8B8"
   },
   "source": [
    "## Image Opertaions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUpU8BrgIEUT"
   },
   "source": [
    "**Crop the image**\n",
    "\n",
    "- In the image we can select a particular part of the image\n",
    "\n",
    "- Image has pixels of rows and columns\n",
    "\n",
    "- slice around rows slice around the column values of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "AX2kd2vqzyA6",
    "outputId": "53da7523-1e39-4d42-ed31-4fab049d98c1"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "image=cv2.imread(\"/content/Benjamin-Franklin.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyFKFtKvIxmc"
   },
   "source": [
    "- if I want to crop Benjamin eye,We need to pixel values\n",
    "\n",
    "-  How much Height I need to choose ?\n",
    "\n",
    "-  How much width I need to choose ?\n",
    "\n",
    "- Co- ordinate axis visualise using Matplotlib library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "gNVbjsmVIOt1",
    "outputId": "73e9c392-bfd0-43ec-fe14-b22c4fb35391"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "afUq__teIW2B",
    "outputId": "cd3ada47-53f7-455c-a717-c1a6c53e46a3"
   },
   "outputs": [],
   "source": [
    "cropped_image=image[100:120, 250:320]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(cropped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AAlnCLuJkTw"
   },
   "source": [
    "**Image Masking**\n",
    "\n",
    "- We extracted Benjamin eye\n",
    "\n",
    "- Now I want to mask Benjamin Eye with Complete RED or Blue or Green or some Other color\n",
    "\n",
    "- Image represents with Numbers which means pixel values\n",
    "\n",
    "- Benjamin Imgae shape 570 X 547\n",
    "\n",
    "  - Height=570 which indicates Number of rows (Y axis)\n",
    "\n",
    "  - Width =547 which indicates Number of columns (X-axis)\n",
    "\n",
    "\n",
    "- So Benjamin eye Needs\n",
    "\n",
    "  - 100rows  to 120 rows Height\n",
    "\n",
    "  - 250columns to 320 columns width\n",
    "\n",
    "\n",
    "- These croped rows and columns has different values\n",
    "\n",
    "- We already know Image represents (R,G,B)\n",
    "\n",
    "- Values varies from 0 to 255\n",
    "\n",
    "  - (255,0,0)  represnts RED\n",
    "\n",
    "  - (0,255,0)  represents Green\n",
    "\n",
    "  - (0,0,255) represents Blue\n",
    "\n",
    "  - (0,0,0)  all are zero means Black\n",
    "\n",
    "  - (255,255,255)  means White\n",
    "\n",
    "\n",
    "- We will replace Benjamin eye pixel values with above values and check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIFIyeIpL39x"
   },
   "source": [
    "**Red Masking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "plGlU1MsJQg6",
    "outputId": "fd96cb24-72e7-4cec-836d-97aab5a3ea0b"
   },
   "outputs": [],
   "source": [
    "image[100:120, 250:320]=(255,0,0)  # RGB\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGFjrLsfL7sY"
   },
   "source": [
    "**You Try for others**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kHN3bklMNpZ"
   },
   "source": [
    "**resize The Image**\n",
    "\n",
    "- we know that Image means numbers which is called as pixel values\n",
    "\n",
    "- We can reisze the image by decreasing the dimensions of the image\n",
    "\n",
    "- Here Dimensions means changing the Height and width\n",
    "\n",
    "- We can say changing the shape also\n",
    "\n",
    "- If you decrease the shape or increase the shape The image might become blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "MMorPbKALvO7",
    "outputId": "6cd62e46-ed48-4943-9450-cefd4b657cfa"
   },
   "outputs": [],
   "source": [
    "dim=(47,50)  # (x,y)\n",
    "resized_lower = cv2.resize(image, dim)\n",
    "print(resized_lower.shape)  # (y,x)\n",
    "plt.imshow(resized_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "ABqoaTmDM-th",
    "outputId": "ef8eec9b-a1c8-4dce-8bdf-1014796e8274"
   },
   "outputs": [],
   "source": [
    "dim=(1000,1000)\n",
    "resized_upper = cv2.resize(image, dim)\n",
    "print(resized_upper.shape)\n",
    "plt.imshow(resized_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89fCHPH_Nukn"
   },
   "source": [
    "**Flip The image**\n",
    "\n",
    "Flipping an image in OpenCV can be done using the cv2.flip function. This function takes two arguments:\n",
    "\n",
    "- src: The source image you want to flip.\n",
    "\n",
    "- flipCode: A code that specifies how to flip the image:\n",
    "\n",
    "  - 0 for flipping around the X-axis (vertical flip).\n",
    "\n",
    "  - 1 for flipping around the Y-axis (horizontal flip).\n",
    "\n",
    "  - -1 for flipping around both axes (vertical and horizontal flip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grFWo8z_NVx8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "k0XXnZYfN_MY",
    "outputId": "0e77d886-112a-43be-abcb-6b0d21f9fb3d"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread('/content/Benjamin-Franklin.jpg')\n",
    "\n",
    "# Flip the image vertically (around the X-axis)\n",
    "flipped_vertically = cv2.flip(image, 0)\n",
    "\n",
    "# Flip the image horizontally (around the Y-axis)\n",
    "flipped_horizontally = cv2.flip(image, 1)\n",
    "\n",
    "# Flip the image both vertically and horizontally (around both axes)\n",
    "flipped_both = cv2.flip(image, -1)\n",
    "\n",
    "# Display the original and flipped images\n",
    "cv2_imshow(image)\n",
    "cv2_imshow(flipped_vertically)\n",
    "cv2_imshow(flipped_horizontally)\n",
    "cv2_imshow(flipped_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "id": "CP63WPdiOIiH",
    "outputId": "e214aab2-a779-43a1-c175-2561dcc787ad"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread('/content/Benjamin-Franklin.jpg')\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Flip the image vertically (around the X-axis)\n",
    "flipped_vertically = cv2.flip(image, 0)\n",
    "\n",
    "# Flip the image horizontally (around the Y-axis)\n",
    "flipped_horizontally = cv2.flip(image, 1)\n",
    "\n",
    "# Flip the image both vertically and horizontally (around both axes)\n",
    "flipped_both = cv2.flip(image, -1)\n",
    "\n",
    "# Display the original and flipped images\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Flipped Vertically')\n",
    "plt.imshow(flipped_vertically)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Flipped Horizontally')\n",
    "plt.imshow(flipped_horizontally)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Flipped Both Vertically and Horizontally')\n",
    "plt.imshow(flipped_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MIqIh0xOm9P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01wqdQ_fPrXp"
   },
   "source": [
    "**Image Data augmentation**\n",
    "\n",
    "Image data augmentation is a technique used to artificially increase the size of a training dataset by creating modified versions of images in the dataset. This helps improve the robustness and performance of machine learning models, especially in computer vision tasks. Common augmentation techniques include rotations, translations, flips, brightness adjustments, zooms, and more.\n",
    "\n",
    "Package: Tensorflow\n",
    "\n",
    "Method: ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LL5w_02IPuxW",
    "outputId": "6a34fe93-420c-447f-b400-b4ea15a79f2b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load an image using OpenCV\n",
    "image = cv2.imread('/content/Benjamin-Franklin.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (128, 128))\n",
    "\n",
    "# Create an instance of ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Expand dimensions to match the input shape expected by the generator\n",
    "image = image.reshape((1,) + image.shape)\n",
    "\n",
    "# Generate batches of augmented images\n",
    "aug_iter = datagen.flow(image, batch_size=1)\n",
    "\n",
    "# Plot some augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    batch = next(aug_iter)\n",
    "    aug_image = batch[0].astype('uint8')\n",
    "    plt.imshow(aug_image)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQnnu20PPzK-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
